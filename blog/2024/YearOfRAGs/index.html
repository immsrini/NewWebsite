<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Leveraging Retrieval-Augmented Generation (RAG) with Large Language Models | Mukundhan Srinivasan </title> <meta name="author" content="Mukundhan Srinivasan"> <meta name="description" content="Transforming Enterprise Solutions"> <meta name="keywords" content="Mukund, Mukundhan, Srinivasan, immsrini"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://immsrini.github.io/blog/2024/YearOfRAGs/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Mukundhan Srinivasan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Leveraging Retrieval-Augmented Generation (RAG) with Large Language Models</h1> <p class="post-meta"> January 01, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/math-code"> <i class="fa-solid fa-hashtag fa-sm"></i> math&amp;code,</a>   <a href="/blog/tag/machinelearning"> <i class="fa-solid fa-hashtag fa-sm"></i> MachineLearning</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In anticipation of 2024 being the year of RAGs, here is quick getting started and 101 on this optimisation method.</p> <p>In an era where the deluge of information grows exponentially, enterprises are increasingly seeking innovative solutions to harness vast datasets for actionable insights. One of the most promising advancements in this domain is the integration of Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). This powerful combination offers a paradigm shift in how businesses access, process, and leverage information to drive decision-making, enhance customer experiences, and streamline operations. This blog explores the implementation of RAG with LLMs, underscoring their importance as enterprise tools through practical code examples.</p> <h4 id="understanding-rag-and-its-enterprise-significance">Understanding RAG and Its Enterprise Significance</h4> <p>Retrieval-Augmented Generation combines the best of two worlds: the retrieval capabilities of information retrieval systems and the generative prowess of LLMs. By first fetching relevant documents or data snippets in response to a query and then feeding this information into an LLM to generate answers, RAG models can provide more accurate, context-rich, and informative responses than standalone LLMs. This approach is invaluable for enterprises dealing with complex queries that require deep domain knowledge or historical context, bridging the gap between vast data repositories and the need for nuanced, real-time insights.</p> <h4 id="why-rags-are-indispensable-for-enterprises">Why RAGs are Indispensable for Enterprises:</h4> <ul> <li> <strong>Enhanced Accuracy and Contextual Awareness</strong>: RAGs provide answers that are not only contextually aware but also deeply rooted in the specificities of the queried domain, making them highly accurate.</li> <li> <strong>Scalability and Efficiency</strong>: They allow businesses to scale their information retrieval and processing capabilities without linear increases in computational costs, handling vast amounts of data efficiently.</li> <li> <strong>Dynamic Knowledge Integration</strong>: Enterprises can continuously update their databases, ensuring the RAG system always draws from the most current information, keeping insights relevant and timely.</li> </ul> <h4 id="implementing-rag-with-llms-a-practical-approach">Implementing RAG with LLMs: A Practical Approach</h4> <p>While implementing a RAG system from scratch can be complex, leveraging existing frameworks like Hugging Face’s Transformers library simplifies this process. Below is a simplified example to illustrate how one might begin implementing a RAG system using Python. This example assumes you have access to a suitable dataset and a pretrained LLM.</p> <h3 id="step-1-set-up-your-environment">Step 1: Set Up Your Environment</h3> <p>First, ensure you have the necessary libraries installed. You can install Hugging Face’s Transformers and Datasets libraries, which offer out-of-the-box support for RAG implementations.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>transformers datasets
</code></pre></div></div> <h3 id="step-2-load-your-data">Step 2: Load Your Data</h3> <p>For this example, let’s assume you’re using a dataset of historical customer feedback to answer queries about customer satisfaction trends.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>

<span class="c1"># Load your dataset (this is a placeholder for your actual data loading mechanism)
</span><span class="n">dataset</span> <span class="o">=</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="sh">"</span><span class="s">your_dataset_name</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="step-3-initialize-rag">Step 3: Initialize RAG</h3> <p>Using the Transformers library, you can initialize a RAG model along with a tokenizer. For demonstration, we’ll use a dummy dataset name and a generic RAG-Token model. In practice, you’d select a model appropriate for your specific domain and data.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">RagTokenizer</span><span class="p">,</span> <span class="n">RagTokenForGeneration</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RagTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">facebook/rag-token-nq</span><span class="sh">"</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RagTokenForGeneration</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span><span class="sh">"</span><span class="s">facebook/rag-token-nq</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Example query
</span><span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What are the main factors driving customer dissatisfaction in Q2?</span><span class="sh">"</span>

<span class="c1"># Tokenize input for RAG
</span><span class="n">inputs</span> <span class="o">=</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Generate response using RAG
</span><span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">generate</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">])</span>

<span class="c1"># Decode and print the answer
</span><span class="nf">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</code></pre></div></div> <h3 id="step-4-integrate-with-your-data-retrieval-system">Step 4: Integrate with Your Data Retrieval System</h3> <p>In practice, you would integrate the model with your data retrieval system, ensuring it can pull relevant documents or data snippets based on the query before feeding this information into the RAG model. This step is highly specific to your data infrastructure and the nature of your queries.</p> <h4 id="the-business-impact-of-rag-enhanced-llms">The Business Impact of RAG-Enhanced LLMs</h4> <p>Integrating RAG with LLMs can significantly enhance various enterprise functions, including:</p> <ul> <li>Customer Support: Providing precise, context-aware answers to customer queries by retrieving and synthesizing information from product manuals, FAQs, and customer interaction histories.</li> <li>Market Research: Aggregating and summarizing insights from numerous sources to identify trends, opportunities, and threats.</li> <li>Regulatory Compliance: Quickly parsing and understanding vast regulatory texts to ensure compliance and identify relevant changes in legislation.</li> </ul> <h4 id="a-future-empowered-by-rag-and-llms">A Future Empowered by RAG and LLMs</h4> <p>The synergy between RAG and LLMs heralds a new era of enterprise efficiency, intelligence, and adaptability. By effectively marrying the depth and dynamism of large datasets with the nuanced generative capabilities of LLMs, businesses can unlock unprecedented value from their information assets. As technology continues to evolve, the potential applications of RAG-enhanced LLM</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/The-Intersection-of-AI,-Society,-and-the-Economy/">How AI and Large Language Models Forge the Future of Value</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/DPO_bestPaper_Neurips/">DPO v. PPO</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/funcProg/">Embracing Functional Programming</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/blackhole/">Exploring the Depths of the Black Hole Information Paradox</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/BeautyofCalc/">The Elegance of Calculus</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Mukundhan Srinivasan. Powered by <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> and hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: July 28, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-42D6SVWV0W"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-42D6SVWV0W");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>